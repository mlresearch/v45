---
title: Similarity-based Contrastive Divergence Methods for Energy-based Deep Learning
  Models
abstract: 'Energy-based deep learning models like Restricted Boltzmann Machines are
  increasingly used for real-world applications. However, all these models inherently
  depend on the Contrastive Divergence (CD) method for training and maximization of
  log likelihood of generating the given data distribution. CD, which internally uses
  Gibbs sampling, often does not perform well due to issues such as biased samples,
  poor mixing of Markov chains and high-mass probability modes. Variants of CD such
  as PCD, Fast PCD and Tempered MCMC have been proposed to address this issue. In
  this work, we propose a new approach to CD-based methods, called Diss-CD, which
  uses dissimilar data to allow the Markov chain to explore new modes in the probability
  space. This method can be used with all variants of CD (or PCD), and across all
  energy-based deep learning models. Our experiments on using this approach on standard
  datasets including MNIST, Caltech-101 Silhouette and Synthetic Transformations,
  demonstrate the promise of this approach, showing fast convergence of error in learning
  and also a better approximation of log likelihood of the data. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Sankar15
month: 0
firstpage: 391
lastpage: 406
page: 391-406
sections: 
author:
- given: Adepu Ravi
  family: Sankar
- given: Vineeth N
  family: Balasubramanian
date: 2016-02-25
address: Hong Kong
publisher: PMLR
container-title: Asian Conference on Machine Learning
volume: '45'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 2
  - 25
pdf: http://proceedings.mlr.press/v45/Sankar15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
