---
title: One-Pass Multi-View Learning
abstract: 'Multi-view learning has been an important learning paradigm where data
  come from multiple channels or appear in multiple modalities. Many approaches have
  been developed in this field, and have achieved better performance than single-view
  ones. Those approaches, however, always work on small-size datasets with low dimensionality,
  owing to their high computational cost. In recent years, it has been witnessed that
  many applications involve large-scale multi-view data, e.g., hundreds of hours of
  video (including visual, audio and text views) is uploaded to YouTube every minute,
  bringing a big challenge to previous multi-view algorithms. This work  concentrates
  on the large-scale multi-view learning for classification and proposes the One-Pass
  Multi-View (OPMV) framework which goes through the training data only once without
  storing the entire training examples. This approach jointly optimizes the composite
  objective functions with consistency linear constraints for different views. We
  verify, both theoretically and empirically, the effectiveness of the proposed algorithm.   '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Zhu15
month: 0
tex_title: One-Pass Multi-View Learning
firstpage: 407
lastpage: 422
page: 407-422
order: 407
cycles: false
author:
- given: Yue
  family: Zhu
- given: Wei
  family: Gao
- given: Zhi-Hua
  family: Zhou
date: 2016-02-25
address: Hong Kong
publisher: PMLR
container-title: Asian Conference on Machine Learning
volume: '45'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 2
  - 25
pdf: http://proceedings.mlr.press/v45/Zhu15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
