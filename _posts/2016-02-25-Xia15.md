---
title: Budgeted Bandit Problems with Continuous Random Costs
abstract: 'We study the budgeted bandit problem, where each arm is associated with
  both a reward and a cost. In a budgeted bandit problem, the objective is to design
  an arm pulling algorithm in order to maximize the total reward before the budget
  runs out. In this work, we study both multi-armed bandits and linear bandits, and
  focus on the setting with continuous random costs. We propose an upper confidence
  bound based algorithm for multi-armed bandits and a confidence ball based algorithm
  for linear bandits, and prove logarithmic regret bounds for both algorithms. We
  conduct simulations on the proposed algorithms, which verify the effectiveness of
  our proposed algorithms. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: Xia15
month: 0
tex_title: Budgeted Bandit Problems with Continuous Random Costs
firstpage: 317
lastpage: 332
page: 317-332
sections: 
author:
- given: Yingce
  family: Xia
- given: Wenkui
  family: Ding
- given: Xu-Dong
  family: Zhang
- given: Nenghai
  family: Yu
- given: Tao
  family: Qin
date: 2016-02-25
address: Hong Kong
publisher: PMLR
container-title: Asian Conference on Machine Learning
volume: '45'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 2
  - 25
pdf: http://proceedings.mlr.press/v45/Xia15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
